name: build-idf

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        app: [mesh_node, mesh_root]
        target: [esp32, esp32s3]

    env:
      IDF_VERSION: v5.2.1
      APP_NAME: ${{ matrix.app }}
      TARGET: ${{ matrix.target }}
      # ChatGPT diagnosis (you can override in repo/Org secrets if needed)
      OPENAI_MODEL: gpt-4o-mini
      # If you use an OpenAI-compatible proxy, set OPENAI_BASE_URL as a secret.
      # Otherwise it will default to https://api.openai.com

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Python deps for diagnosis
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # Set up ESP-IDF (official action)
      - name: Setup ESP-IDF ${{ env.IDF_VERSION }}
        uses: espressif/setup-esp-idf@v1
        with:
          version: ${{ env.IDF_VERSION }}
          tools-cache: true

      # Build the selected app
      - name: Build ${{ env.APP_NAME }} (${{ env.TARGET }})
        working-directory: ${{ github.workspace }}/${{ env.APP_NAME }}
        shell: bash
        run: |
          set -euo pipefail
          echo "== Configuring IDF project for $TARGET =="
          idf.py --version
          idf.py fullclean
          idf.py set-target "$TARGET"
          # Keep a complete build log for diagnosis
          idf.py build 2>&1 | tee "${APP_NAME}.log"
          # Stash paths for artifacts
          echo "BUILD_DIR=$(pwd)/build" >> $GITHUB_ENV
          echo "LOG_FILE=$(pwd)/${APP_NAME}.log" >> $GITHUB_ENV

      - name: Upload artifacts (bins, elf, logs)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.APP_NAME }}-${{ env.TARGET }}-artifacts
          path: |
            ${{ env.BUILD_DIR }}/**/*.bin
            ${{ env.BUILD_DIR }}/**/*.elf
            ${{ env.LOG_FILE }}
          if-no-files-found: warn
          retention-days: 7

      # ---- ChatGPT diagnosis step ----
      - name: ChatGPT diagnosis
        if: always()
        shell: bash
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_BASE_URL: ${{ secrets.OPENAI_BASE_URL }}
          OPENAI_MODEL: ${{ env.OPENAI_MODEL }}
          LOG: ${{ env.LOG_FILE }}
          APP_NAME: ${{ env.APP_NAME }}
          TARGET: ${{ env.TARGET }}
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, sys, json, requests

          api_key = os.getenv("OPENAI_API_KEY", "")
          if not api_key:
              print("ChatGPT diagnosis skipped: OPENAI_API_KEY not set.")
              sys.exit(0)

          base = os.getenv("OPENAI_BASE_URL", "https://api.openai.com")
          model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
          log_path = os.getenv("LOG", "")
          app = os.getenv("APP_NAME", "app")
          target = os.getenv("TARGET", "esp32")

          try:
              with open(log_path, "r", encoding="utf-8", errors="ignore") as f:
                  log = f.read()
          except Exception as e:
              print(f"ChatGPT diagnosis: could not read log file: {e}")
              sys.exit(0)

          # Send the tail of the log (most relevant recent lines)
          tail = log[-4000:]

          system_msg = (
              "You are an expert ESP-IDF/ESP32 build assistant. "
              "Given a failing build log tail, identify the FIRST root cause error(s), "
              "explain in 3-6 concise bullet points, and propose exact code or config fixes. "
              "If success, say 'Build succeeded' briefly."
          )
          user_msg = f"App: {app}\nTarget: {target}\n\nLog tail:\n```\n{tail}\n```"

          url = f"{base.rstrip('/')}/v1/chat/completions"
          headers = {
              "Authorization": f"Bearer {api_key}",
              "Content-Type": "application/json",
          }
          payload = {
              "model": model,
              "messages": [
                  {"role": "system", "content": system_msg},
                  {"role": "user", "content": user_msg},
              ],
              "temperature": 0.2,
          }

          try:
              r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)
              r.raise_for_status()
              data = r.json()
              text = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
              print("\n===== ChatGPT Diagnosis =====\n")
              print(text or "(no response text)")
              print("\n===== End Diagnosis =====\n")
          except Exception as e:
              print(f"ChatGPT diagnosis request failed: {e}")
              # Do not fail the job just because diagnosis failed
              sys.exit(0)
          PY
